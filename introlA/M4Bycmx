
有数据才可以做统计分析，下面参考的案例，
=芬兰某商业银行的软件维护数据统计分析=
先看总体分析结论，再看从原始数据到分析结果的步骤。
==总结报告==
===背景===
银行管理层理解，如果不监控维护工作量，很可能会失控
例如，有些软件系统因为在开发期间没有管理好（例如，引起很多缺陷），就会影响到后面维护工作量提升
所以从86年开始，都一直统计软件维护相关数据。
*从1987年到1995年，银行开发了250 IBM应用软件，其中部分是系统迁移（从原来的BULL主机迁移到IBM主机）
*從中抽取了67有充分数据的应用软件，做统计分析。

希望解答以下问题:
#那些因素主要影响软件维护工作量（成本）
#有什么办法可以降低维护成本？
#利用预测模型，预估下一年度的维护成本

===1.影响维护工作量的主因 ===
:::<<表5.4里>>

[[文件:maxwell t5.4.jpg]]

五个因素代表了62%的原因:
*第一因素
是软件的规模大小占27%
你可能疑问为什么没有看到缺陷 密度？
因为缺少密度与规模大小，息息相关相关，
所以只需要考虑规模便可以
*第二因素
批量处理的集成度
*第三因素
是哪一类应用软件，看图5.2
:::<<图5.2>>

[[文件:maxwell f5.2.jpg]]

股票买卖相关的维护工作量最高
一般银行应用，例如捐款转钱最低
原因：股票买卖的规则很复杂，嗯，大家大家都想你高竞争力竞争力，导致没有标准的模式

*第四因素
是变更管理的灵活性
如果应用很依赖其他系统更多的利益相关者，
需要商户协商达成一致才可以变更
维护成本就低了
*第五因素
最后一个因素是应用软件投产后多少个月大概每年降低17.4%
例如，如果第一年是100小时，第二年就会降到82.6小时，下一年会降到68.2小时

===2.什么办法可以降低维护成本===
初步分析发现
使用Telon语言的系统要维护工作量较少，
只要1.19小时/FP，
相对不使用Telon的软件系统需要是2.47小时/FP。

针对使用Telon语言的十一个系统统计分析：
*发现语言的百分比与维护工作量正相关;使用的比例越高，维护工作量越低
*用功能点规模归一以后的维护工作量，也是强相关
::<<详见 表 5.6>>

[[文件:maxwell t5.6.jpg]]

===3.预估下一年度的维护成本===
统计分析，除了帮我们洞察那些主要影响因素外，也可以帮我们做预测:
::<<表格5.5>>

[[文件:maxwell t5.5.jpg]]

但从表格5.5看到预测的准确度低
预测1994年的工作量为例，
用模型预测的准确度还不如直接使用1993的数字

在前面估算章节讨论过，
很多因素影响软件开发的工作量难以准确预估

==数据分析步骤 ==
不用误以为只要有统计分析工具，把项目数据输入，便自动得出上面分析结果。
以下对应每个步骤，用简单例子说明，如想自己动手，使用案例数据，完成整个数据分析过程，请参照Maxwell第5章(详见Ref)。
===汇总数据，并明确每个变量的操作定义===
*本来数据分散在三个电子表单，每个表单有两百多个项目数据，但很多数据不齐全
*最终汇总出67个项目数据，它们都在1993年有数据
*明确每个变量的操作定义(本来数据表都是用芬兰语言，也有很多银行专业术语)，确保大家的理解一致
===使用描述性统计检查数据完整性和正确性===
*用数据总结功能，找出28个变量的均值 / 标准差 / 最大 / 最小:
*发现某些变量最小值是零，不合理。例如： avetrans, disksp, cpu
*有些变量数据不全，为空，请银行经理尽力填上。例如： r1-r10, dbms,tpms
:::<< Example 5.1 (p.209)>>


[[文件:maxwell e5.1.jpg]]

===Creation of New Variables建立新变量===
例：有些项目是在1993年一月份以后才开始维护，
为了要与其他1993年一月份或者以前已开始的项目可以比较，
创建新变量(acorreff)，例如，1993年只是维护了10个月，用了30小时，
就要换成36小时[=(30/10)*12]

===Data Modifications数据修改===
*Identify subsets of Categorical Variables识别同一范畴的变量
*模型选择 - Preliminary Analyses初步分析: 
*Q:哪些因素影响到“年度维护工作量”

===Histograms直方图===
*画柱状图发现维护工作量(acorreff)，规模大小(totfp)，都是极度偏左，
*使用自然对数使它变成较近似正态分布（因为变量不是正态分布，会影响回归分析不准确）
:::<< FIg 5.6 (p.217)>>

[[文件:maxwell f5.6.jpg]]

:::<< Fig 5.8 (p.218)>>

[[文件:maxwell f5.8.jpg]]

===Scatter plot散点图===
*从维护工作量 ln(acorreff) 与规模大小 ln(totfp) 的散点图，看到两者之间有线性关系
:::<< Fig 5.29 (p.228)>>

[[文件:maxwell f5.29.jpg]]

===针对某个变量看各种分组的数量和维护工作量===
例如，在内部业务部分组：
:::<< Example 5.14 (p.238)>>

[[文件:maxwell e5.14.jpg]]

*存款业务(Deposit)的维护工作量最高
*户口管理(Account)要维护工作量最低

===相关(Correlation)分析===
两变量的相关从-1 到 1， 关于这系数的意义，可参考附件。因为如果两个变量是强相关，
如果把这两个高度相关的变量放在一起做预测模型，就会会导致模型不稳定，所以要预先删除、处理。下表是相关系数大于0.51 的汇总表：
:::<< Tab 5.9 (p.241)>>

[[文件:maxwell t5.9.jpg]]

例如，
因为r2和r3强相关，它们也与其他变量相关，所以决定把r2和r3剔除

===回归分析===
*利用以下连续变量做回归分析 [Y是维护工作量(lacorreff)]
::(ltotfp, pcobol, pjcl, ageend, ladefect)
:ln(acorreff) = 2.532 + 0.541*(ltotfp)    
::Adj. R-square = 0.27

*最终得出以下5变量回归模型 
:ln(acorreff) = 3.768 + 0.555*ln(totfp) + r9_coef + submorg_coef + r3_coef - 0.016*ageend    
::Adj. R-square = 0.619
* r10 因与submorg强相关，被剔除，剩下5变量
* r9, submorg, r3 因为是分组数据，系数会依据类型，按下表选对应系数：
:::<< Table 5.14 (p.257)>>

[[文件:maxwell t5.14.jpg]]

===使用回归模型预测===

===分析使用对维护工作量的作用===


=回顾与总结=


=附件=
==项目变量列表 ==


==X 与 Y 相关性图==
*完美负相关(-1):
::<<Fig 6.7 ,pg291>>

[[文件:maxwell f6.7.jpg]]

*零相关(0):
::<<Fig 6.9 ,pg292>>

[[文件:maxwell f6.9.jpg]]

*完美正相关(+1):
::<<Fig 6.8 ,pg292>>

[[文件:maxwell f6.8.jpg]]

==Prunning by Wrapper==

当我们收集到一定数量的项目数据，就可以尝试做组织级的数据分析。很多分析数据时，没有考虑项目之间的差异，假定项目的特性都类似，然后直接就用统计分析方法，求模型的方程式参数。<br>
例如下图，6个项目是5个迭代的系统测试密度数据，你觉得把6个项目的缺陷密度放在一起分析合适吗？很明显两个项目缺陷比较低，有些很散，所以如果没有考虑项目之间的差异，直接总体分析就会变成很宽，比如对A的缺陷比较低，没有什么参考意义。

::<<handDrawPicture.jpg>> to be provided

除了我们要细分项目就是要考虑保留那些项目参数（影响因素），很多时候我们看到一些公司级的数据分析，都是一大堆表，可能要有二三十个变量来分析，从模型出来的变量越多，其实不是好事：
#可能做了过度的调整，导致那个预测模型没有预测的意义，只适合用在这堆项目数据上；
#变量多也会导致要花很多精力去收集数据，不划算。
#使用模型的人也很难理解这个模型的意义，不知道如何去使用。<br>

我们在前面EST2里的乐高模型数据案例，简单用了两个变量来做个预测模型，一是积木的数量，即它的规模大小；二是团队人数；可以比较好地估计工作量，这是比较理想的模型。<br>
所以当开始时，收集到很多变量，我们就需要利用数据分析删除一些意义不大的变量。<br>
怎么挑选呢？<br>
比如一个方式是用wrapper机械性地去挑选，如果增加一个变量准确度更好就增加，如果不是就不增加，直到挑选出最佳的搭配。

[[文件:chen f2.jpg|600px]]

[[文件:chen f3.jpg|600px]]


=References=
1. Maxwell, Katrina: ''Applied Statistics for Software Managers'' Prentice-Hall 2002.<br>
2. Chen, Zhihao: "Finding the Right Data for Software Cost Modeling" IEEE Software Nov/Dec 2005
:::---===<<< END >>>===---

